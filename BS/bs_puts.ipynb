{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a8bd54",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86868bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393b48f",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine data\n",
    "PATH_TO_FILE_1 = \"../raw data/aapl_2016_2020.csv\"\n",
    "PATH_TO_FILE_2 = \"../raw data/aapl_2021_2023.csv\"\n",
    "half_1 = pd.read_csv(PATH_TO_FILE_1, low_memory=False)\n",
    "half_2 = pd.read_csv(PATH_TO_FILE_2, low_memory=False)\n",
    "df = pd.concat([half_1, half_2], ignore_index=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Option type\n",
    "option_type = \"put\"\n",
    "\n",
    "# Convert Unix timestamps to datetime\n",
    "df['QUOTE_DATETIME'] = pd.to_datetime(df['[QUOTE_UNIXTIME]'], unit='s')\n",
    "df['EXPIRE_DATETIME'] = pd.to_datetime(df['[EXPIRE_UNIX]'], unit='s')\n",
    "\n",
    "# Load underlying price data for volatility computation\n",
    "underlying_prices = df[['QUOTE_DATETIME', '[UNDERLYING_LAST]']].drop_duplicates().set_index('QUOTE_DATETIME').sort_index()\n",
    "\n",
    "# Function to compute historical volatility\n",
    "def historical_volatility(series, window=20):\n",
    "    return np.sqrt(252) * series.pct_change().rolling(window=window).std()\n",
    "\n",
    "# Compute 20-day historical volatility\n",
    "underlying_prices['hist_vol_20d'] = historical_volatility(underlying_prices['[UNDERLYING_LAST]'])\n",
    "underlying_prices.dropna(inplace=True)\n",
    "\n",
    "# Merge historical volatility back into main dataframe\n",
    "df = df.merge(underlying_prices[['hist_vol_20d']], left_on='QUOTE_DATETIME', right_index=True, how='inner')\n",
    "\n",
    "# Columns to numeric conversion: choose columns based on option type\n",
    "if option_type == 'call':\n",
    "    numeric_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n",
    "                    '[C_THETA]', '[C_RHO]', '[C_BID]', '[C_ASK]']\n",
    "else:\n",
    "    numeric_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]',\n",
    "                    '[P_THETA]', '[P_RHO]', '[P_BID]', '[P_ASK]']\n",
    "\n",
    "essential_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', 'hist_vol_20d', '[C_BID]', '[C_ASK]']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(subset=essential_cols, inplace=True)\n",
    "\n",
    "# Calculate mid-price based on option type\n",
    "if option_type == 'call':\n",
    "    df['CALL_EQUI_PRICE'] = (df['[C_BID]'] + df['[C_ASK]']) / 2\n",
    "else:\n",
    "    df['PUT_EQUI_PRICE'] = (df['[P_BID]'] + df['[P_ASK]']) / 2\n",
    "\n",
    "# Drop rows with missing essential data (dynamically chosen based on option type)\n",
    "essential_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', 'hist_vol_20d']\n",
    "if option_type == 'call':\n",
    "    essential_cols.append('CALL_EQUI_PRICE')\n",
    "else:\n",
    "    essential_cols.append('PUT_EQUI_PRICE')\n",
    "df.dropna(subset=essential_cols, inplace=True)\n",
    "\n",
    "# Prepare option data based on the option type\n",
    "if option_type == 'call':\n",
    "    option_cols = ['[UNDERLYING_LAST]', '[STRIKE]', '[DTE]', 'hist_vol_20d', \n",
    "                   '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]', '[C_THETA]', '[C_RHO]', 'CALL_EQUI_PRICE']\n",
    "    col_rename = ['underlying_price', 'strike_price', 'days_to_expiry', 'hist_volatility', \n",
    "                  'delta', 'gamma', 'vega', 'theta', 'rho', 'equilibrium_price']\n",
    "    output_file = 'processed_calls_data.csv'\n",
    "    model_file = 'call-mlp1.h5'\n",
    "else:\n",
    "    option_cols = ['[UNDERLYING_LAST]', '[STRIKE]', '[DTE]', 'hist_vol_20d', \n",
    "                   '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]', '[P_RHO]', 'PUT_EQUI_PRICE']\n",
    "    col_rename = ['underlying_price', 'strike_price', 'days_to_expiry', 'hist_volatility', \n",
    "                  'delta', 'gamma', 'vega', 'theta', 'rho', 'equilibrium_price']\n",
    "    output_file = 'processed_puts_data.csv'\n",
    "    model_file = 'put-mlp1.h5'\n",
    "\n",
    "option_df = df[option_cols].copy()\n",
    "option_df.columns = col_rename\n",
    "\n",
    "# Normalize strike price and compute time to expiry in years\n",
    "option_df['strike_price'] = option_df['strike_price']\n",
    "option_df['time_to_expiry'] = option_df['days_to_expiry'] / 365\n",
    "option_df.drop('days_to_expiry', axis=1, inplace=True)\n",
    "\n",
    "print(option_df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e7c8f",
   "metadata": {},
   "source": [
    "## Black-Scholes Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Scholes formula for European Put Option\n",
    "def black_scholes_put(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    S: underlying price\n",
    "    K: strike price\n",
    "    T: time to expiry (in years)\n",
    "    r: risk-free interest rate\n",
    "    sigma: volatility (standard deviation of log returns)\n",
    "    \"\"\"\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return np.nan  # avoid invalid math\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    put_price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    return put_price\n",
    "\n",
    "# Assumed constant risk-free rate (can be updated if you have data)\n",
    "risk_free_rate = 0.0243  # 2%\n",
    "\n",
    "# Apply Black-Scholes formula row-wise\n",
    "option_df['bs_price'] = option_df.apply(\n",
    "    lambda row: black_scholes_put(\n",
    "        S=row['underlying_price'],\n",
    "        K=row['strike_price'],\n",
    "        T=row['time_to_expiry'],\n",
    "        r=risk_free_rate,\n",
    "        sigma=row['hist_volatility']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(option_df[['equilibrium_price', 'bs_price']].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa215662",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between predicted and actual prices\n",
    "bs_diff = option_df['bs_price'] - option_df['equilibrium_price']\n",
    "\n",
    "# Absolute and percentage errors\n",
    "abs_error = np.abs(bs_diff)\n",
    "percent_error = 100 * bs_diff / option_df['equilibrium_price']\n",
    "abs_percent_error = np.abs(percent_error)\n",
    "\n",
    "# Compute error metrics\n",
    "mean_error = bs_diff.mean()\n",
    "std_error = bs_diff.std()\n",
    "median_error = np.median(bs_diff)\n",
    "mae = abs_error.mean()\n",
    "rmse = np.sqrt(np.mean(bs_diff**2))\n",
    "mape = abs_percent_error.mean()\n",
    "max_error = bs_diff.max()\n",
    "min_error = bs_diff.min()\n",
    "\n",
    "# R²: drop rows with NaNs\n",
    "valid = option_df[['equilibrium_price', 'bs_price']].dropna()\n",
    "r2 = r2_score(valid['equilibrium_price'], valid['bs_price'])\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\n--- Black-Scholes Error Metrics ---\")\n",
    "print(f\"Mean Error: {mean_error:.4f}\")\n",
    "print(f\"Median Error: {median_error:.4f}\")\n",
    "print(f\"Standard Deviation of Error: {std_error:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Max Error: {max_error:.4f}\")\n",
    "print(f\"Min Error: {min_error:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Plot histogram of errors\n",
    "bins = np.arange(-5, 5, 0.05)\n",
    "# Plot histogram of absolute errors\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(bs_diff, bins = np.arange(-5, 5, 0.05), alpha=0.7)\n",
    "plt.xlabel(\"Error (Predicted - Actual)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Put Black-Scholes Prediction Error Distribution\")\n",
    "plt.grid(True)\n",
    "plt.xlim([-5, 5])\n",
    "plt.show()\n",
    "\n",
    "# Filter out zero or near-zero actual prices to avoid divide-by-zero\n",
    "valid_mask = option_df['equilibrium_price'].abs() > 0\n",
    "ep = option_df['equilibrium_price']\n",
    "bs = option_df['bs_price']\n",
    "actual_valid = ep[valid_mask]\n",
    "predicted_valid = bs[valid_mask]\n",
    "\n",
    "# Calculate absolute percent errors safely\n",
    "abs_percent_errors = 100 * np.abs((predicted_valid - actual_valid) / actual_valid)\n",
    "\n",
    "# Define function to compute Percent Error within thresholds\n",
    "def compute_pe(abs_percent_errors, threshold):\n",
    "    return np.mean(abs_percent_errors <= threshold) * 100\n",
    "\n",
    "# Compute and print PE5, PE10, PE20\n",
    "print(f\"PE5:  {compute_pe(abs_percent_errors, 5):.2f}%\")\n",
    "print(f\"PE10: {compute_pe(abs_percent_errors, 10):.2f}%\")\n",
    "print(f\"PE20: {compute_pe(abs_percent_errors, 20):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
