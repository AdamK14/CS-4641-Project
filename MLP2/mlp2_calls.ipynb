{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine data\n",
    "PATH_TO_FILE_1 = \"../raw data/aapl_2016_2020.csv\"\n",
    "PATH_TO_FILE_2 = \"../raw data/aapl_2021_2023.csv\"\n",
    "half_1 = pd.read_csv(PATH_TO_FILE_1, low_memory=False)\n",
    "half_2 = pd.read_csv(PATH_TO_FILE_2, low_memory=False)\n",
    "df = pd.concat([half_1, half_2], ignore_index=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Option type\n",
    "option_type = \"put\"\n",
    "\n",
    "# Convert Unix timestamps to datetime\n",
    "df['QUOTE_DATETIME'] = pd.to_datetime(df['[QUOTE_UNIXTIME]'], unit='s')\n",
    "df['EXPIRE_DATETIME'] = pd.to_datetime(df['[EXPIRE_UNIX]'], unit='s')\n",
    "\n",
    "# Load underlying price data for volatility computation\n",
    "underlying_prices = df[['QUOTE_DATETIME', '[UNDERLYING_LAST]']].drop_duplicates().set_index('QUOTE_DATETIME').sort_index()\n",
    "\n",
    "# Function to compute historical volatility\n",
    "def historical_volatility(series, window=20):\n",
    "    return np.sqrt(252) * series.pct_change().rolling(window=window).std()\n",
    "\n",
    "# Compute 20-day historical volatility\n",
    "underlying_prices['hist_vol_20d'] = historical_volatility(underlying_prices['[UNDERLYING_LAST]'])\n",
    "underlying_prices.dropna(inplace=True)\n",
    "\n",
    "# Merge historical volatility back into main dataframe\n",
    "df = df.merge(underlying_prices[['hist_vol_20d']], left_on='QUOTE_DATETIME', right_index=True, how='inner')\n",
    "\n",
    "# For call options, use the call columns; we want to predict best_bid ([C_BID]) and best_offer ([C_ASK]).\n",
    "if option_type == 'call':\n",
    "    numeric_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n",
    "                    '[C_THETA]', '[C_RHO]', '[C_BID]', '[C_ASK]']\n",
    "else:\n",
    "    numeric_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]',\n",
    "                    '[P_THETA]', '[P_RHO]', '[P_BID]', '[P_ASK]']\n",
    "\n",
    "   \n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "# Drop rows with missing data in the essential columns\n",
    "essential_cols = ['[UNDERLYING_LAST]', '[DTE]', '[STRIKE]', 'hist_vol_20d', '[C_BID]', '[C_ASK]']\n",
    "df.dropna(subset=essential_cols, inplace=True)\n",
    "\n",
    "# Prepare a DataFrame for call options\n",
    "if option_type == \"call\":\n",
    "    option_cols = [\n",
    "        '[UNDERLYING_LAST]', '[STRIKE]', '[DTE]', 'hist_vol_20d', \n",
    "        '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]', '[C_THETA]', '[C_RHO]',\n",
    "        '[C_BID]', '[C_ASK]'\n",
    "    ]\n",
    "    col_rename = [\n",
    "        'underlying_price', 'strike_price', 'days_to_expiry',\n",
    "        'hist_volatility', 'delta', 'gamma', 'vega', 'theta',\n",
    "        'rho', 'best_bid', 'best_offer'\n",
    "    ]\n",
    "    model_file = 'call-mlp2-test.h5'\n",
    "else:\n",
    "    # Finish code here for puts\n",
    "    option_cols = [\n",
    "        '[UNDERLYING_LAST]', '[STRIKE]', '[DTE]', 'hist_vol_20d', \n",
    "        '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]', '[P_RHO]',\n",
    "        '[P_BID]', '[P_ASK]'\n",
    "    ]\n",
    "    col_rename = [\n",
    "        'underlying_price', 'strike_price', 'days_to_expiry',\n",
    "        'hist_volatility', 'delta', 'gamma', 'vega', 'theta',\n",
    "        'rho', 'best_bid', 'best_offer'\n",
    "    ]\n",
    "    model_file = 'put-mlp2-test.h5'\n",
    "\n",
    "option_df = df[option_cols].copy()\n",
    "option_df.columns = col_rename\n",
    "\n",
    "# Normalize strike price and compute time to expiry in years\n",
    "option_df['strike_price'] = option_df['strike_price'] / 1000\n",
    "option_df['time_to_expiry'] = option_df['days_to_expiry'] / 365\n",
    "option_df.drop('days_to_expiry', axis=1, inplace=True)\n",
    "\n",
    "# Save the processed option data to CSV, uncomment if needed\n",
    "# option_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_units_per_layer = [256, 32, 2]\n",
    "layers = 3\n",
    "n_batch = 1024\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['underlying_price', 'strike_price', 'hist_volatility', 'delta', 'gamma', \n",
    "                'vega', 'theta', 'rho', 'time_to_expiry']\n",
    "target_cols = ['best_bid', 'best_offer']\n",
    "\n",
    "X = option_df[feature_cols]\n",
    "y = option_df[target_cols]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create model \n",
    "model = Sequential()\n",
    "\n",
    "# Scale data remains unchanged\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add first layer without ativation\n",
    "model.add(Dense(n_units_per_layer[0], input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Define Keras MLP model using LeakyReLU in subsequent layers\n",
    "for i in range(1, layers - 1):\n",
    "    model.add(Dense(n_units_per_layer[i]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Add last layer\n",
    "model.add(Dense(n_units_per_layer[-1]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Learning rate scheduling remains unchanged\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.1  # reduce LR by 10x every 10 epochs\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=n_batch, validation_split=0.2, verbose=1, callbacks=[lr_callback])\n",
    "\n",
    "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10  # to avoid log(0)\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(np.log(np.array(history.history['loss']) + eps), label='Log Training Loss')\n",
    "plt.plot(np.log(np.array(history.history['val_loss']) + eps), label='Log Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log Loss (Log MSE)')\n",
    "plt.title(f'Training and Validation Log Loss Over Epochs ({option_type} options)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the prediciton equilbrium versus actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_file)\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Cell 8: Optional - Plot Predicted vs Actual Equilibrium Values\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(np.mean(y_test.values, axis=1), np.mean(predictions, axis=1), s=5, alpha=0.5)\n",
    "plt.xlabel('Actual Equilibrium (Mean of Bid & Ask)')\n",
    "plt.ylabel('Predicted Equilibrium (Mean of Bid & Ask)')\n",
    "plt.title('Predicted vs Actual Equilibrium Prices for Call Options')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot predicted bid versus actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Bid Plot\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_test['best_bid'], predictions[:, 0], s=5, alpha=0.5, color=\"red\")\n",
    "plt.xlabel('Actual Best Bid')\n",
    "plt.ylabel('Predicted Best Bid')\n",
    "plt.title('Predicted vs Actual Best Bid Prices')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Offer Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_test['best_offer'], predictions[:, 1], s=5, alpha=0.5, color=\"green\")\n",
    "plt.xlabel('Actual Best Offer')\n",
    "plt.ylabel('Predicted Best Offer')\n",
    "plt.title('Predicted vs Actual Best Offer Prices')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random sample of 10 entries\n",
    "sample_entries = X.sample(10)\n",
    "sample_indices = sample_entries.index\n",
    "\n",
    "# Scale the sample entries and generate predictions\n",
    "sample_scaled = scaler.transform(sample_entries)\n",
    "sample_preds = loaded_model.predict(sample_scaled)\n",
    "\n",
    "# Build a DataFrame to compare actual vs. predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Best Bid': y.loc[sample_indices, 'best_bid'].values,\n",
    "    'Predicted Best Bid': sample_preds[:, 0],\n",
    "    'Actual Best Offer': y.loc[sample_indices, 'best_offer'].values,\n",
    "    'Predicted Best Offer': sample_preds[:, 1]\n",
    "}, index=sample_indices)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Histgoram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_file)\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# ---- Absolute Error Analysis ----\n",
    "abs_errors = np.mean(y_test.values, axis=1) - np.mean(predictions, axis=1)\n",
    "\n",
    "# Plot histogram of absolute errors\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(abs_errors, bins = np.arange(-5, 5, 0.05), alpha=0.7)\n",
    "plt.xlabel(\"Error (Predicted - Actual)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(f\"{option_type} MLP2 Prediction Error Distribution\")\n",
    "plt.grid(True)\n",
    "plt.xlim([-5, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_file)\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate equilibrium price (mean of bid and ask) for actual and predicted values\n",
    "actual_equilibrium = np.mean(y_test.values, axis=1)\n",
    "predicted_equilibrium = np.mean(predictions, axis=1)\n",
    "errors = abs_errors\n",
    "\n",
    "# Calculate metrics based on equilibrium prices\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "mae_eq = mean_absolute_error(actual_equilibrium, predicted_equilibrium)\n",
    "rmse_eq = np.sqrt(mean_squared_error(actual_equilibrium, predicted_equilibrium))\n",
    "max_error_value = np.max(errors)  # Worst overprediction (largest positive error)\n",
    "min_error_value = np.min(errors)  # Worst underprediction (largest negative error)\n",
    "r2 = r2_score(actual_equilibrium, predicted_equilibrium)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Error: {mean_error:.4f}\")\n",
    "print(f\"Standard Deviation of Error: {std_error:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_eq:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_eq:.4f}\")\n",
    "print(f\"Max Error (worst overprediction): {max_error_value:.4f}\")\n",
    "print(f\"Min Error (worst underprediction): {min_error_value:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Create a mask to filter out zero or near-zero actual prices\n",
    "valid_mask = np.abs(actual_equilibrium) > 0\n",
    "\n",
    "# Apply the mask\n",
    "y_true_valid = actual_equilibrium[valid_mask]\n",
    "y_pred_valid = predicted_equilibrium[valid_mask]\n",
    "\n",
    "# Now calculate percent errors without worrying about divide-by-zero\n",
    "abs_percent_errors = 100 * np.abs((y_pred_valid - y_true_valid) / y_true_valid)\n",
    "\n",
    "# PE metrics\n",
    "def compute_pe(abs_percent_errors, threshold):\n",
    "    return np.mean(abs_percent_errors <= threshold) * 100\n",
    "\n",
    "print(f\"PE5:  {compute_pe(abs_percent_errors, 5):.2f}%\")\n",
    "print(f\"PE10: {compute_pe(abs_percent_errors, 10):.2f}%\")\n",
    "print(f\"PE20: {compute_pe(abs_percent_errors, 20):.2f}%\")\n",
    "\n",
    "\n",
    "predictions = loaded_model.predict(X_train_scaled)\n",
    "predicted_equilibrium = np.mean(predictions, axis=1)\n",
    "actual_equilibrium = np.mean(y_train.values, axis=1)\n",
    "\n",
    "# Compute MAE after inverse scaling\n",
    "train_mae_corrected = mean_absolute_error(actual_equilibrium, predicted_equilibrium)\n",
    "print(f\"Train MAE: {train_mae_corrected}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
